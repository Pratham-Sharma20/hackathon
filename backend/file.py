import os
from mistralai import Mistral, SystemMessage, UserMessage
import PyPDF2
from io import BytesIO
import re
from datetime import datetime
import json
from collections import defaultdict
import asyncio
import traceback
from typing import Dict, List, Tuple, Optional, Any 

class EnhancedResumeAnalyzer:
    def __init__(self, mistral_api_key: str):
        """Initialize the Enhanced Resume Analyzer with lightweight analysis capabilities."""
        self.client = Mistral(api_key=mistral_api_key)
        self.skill_categories = {
            'technical_skills': {
                'programming': ['python', 'java', 'javascript', 'c++', 'ruby', 'go'],
                'data': ['sql', 'mongodb', 'postgresql', 'data analysis', 'big data'],
                'cloud': ['aws', 'azure', 'gcp', 'docker', 'kubernetes'],
                'ai_ml': ['machine learning', 'deep learning', 'nlp', 'computer vision']
            },
            'business_skills': {
                'management': ['project management', 'team leadership', 'strategic planning'],
                'analysis': ['business analysis', 'requirements gathering', 'process improvement'],
                'operations': ['operations management', 'supply chain', 'resource planning']
            },
            'soft_skills': {
                'communication': ['presentation', 'writing', 'public speaking'],
                'leadership': ['team building', 'mentoring', 'decision making'],
                'interpersonal': ['collaboration', 'conflict resolution', 'negotiation']
            },
            'domain_specific': {
                'finance': ['financial analysis', 'budgeting', 'forecasting'],
                'marketing': ['digital marketing', 'seo', 'content strategy'],
                'sales': ['sales management', 'account management', 'crm']
            }
        }
        self.section_patterns = {
            'summary': ['summary', 'professional summary', 'profile', 'objective'],
            'experience': ['experience', 'work history', 'employment', 'work experience'],
            'education': ['education', 'academic background', 'qualifications', 'training'],
            'skills': ['skills', 'expertise', 'competencies', 'technical skills'],
            'projects': ['projects', 'key projects', 'portfolio', 'works'],
            'achievements': ['achievements', 'accomplishments', 'awards', 'honors'],
            'certifications': ['certifications', 'certificates', 'licenses'],
            'publications': ['publications', 'research', 'papers'],
            'volunteer': ['volunteer', 'community service', 'social work']
        }
        
        # Common industry keywords that ATS systems flag as positive
        self.industry_keywords = [
            # General professional terms
            'leadership', 'manage', 'team', 'project', 'develop', 'implement', 'strategy',
            'analyze', 'research', 'coordinate', 'collaborate', 'communicate', 'budget',
            'improve', 'create', 'design', 'optimize', 'growth', 'success', 'initiative',
            'deliver', 'achieve', 'increase', 'decrease', 'reduce', 'enhance', 'streamline',
            'efficient', 'effective', 'experience', 'skill', 'knowledge', 'proficient',
            'expert', 'specialist', 'professional', 'certified', 'trained', 'educated',
            'competent', 'responsible', 'accountable', 'proven', 'demonstrated', 'track record',
            
            # Technical terms
            'software', 'hardware', 'network', 'database', 'system', 'application',
            'program', 'code', 'develop', 'engineer', 'architecture', 'infrastructure',
            'security', 'analytics', 'automation', 'integration', 'solution', 'platform',
            'framework', 'methodology', 'agile', 'scrum', 'kanban', 'waterfall',
            'client', 'server', 'web', 'mobile', 'cloud', 'saas', 'paas', 'iaas',
            'api', 'interface', 'frontend', 'backend', 'fullstack', 'devops',
            
            # Business terms
            'revenue', 'profit', 'cost', 'sales', 'market', 'customer', 'client',
            'stakeholder', 'roi', 'kpi', 'metric', 'analysis', 'strategy', 'plan',
            'goal', 'objective', 'target', 'forecast', 'budget', 'finance', 'operation',
            'process', 'procedure', 'policy', 'compliance', 'regulation', 'standard',
            'quality', 'assurance', 'control', 'manage', 'supervise', 'direct', 'lead'
        ]
        
        # Format requirements that ATS systems check for
        self.format_requirements = [
            'consistent formatting',
            'standard resume sections',
            'chronological order',
            'contact information',
            'clear headings',
            'bullet points',
            'quantifiable achievements',
            'specific dates',
            'pdf format'
        ]
        
    def extract_text_from_pdf(self, pdf_content: bytes) -> str:
        """Extract and clean text from PDF with enhanced formatting preservation."""
        try:
            pdf_file = BytesIO(pdf_content)
            reader = PyPDF2.PdfReader(pdf_file)
            text_blocks = []
            for page in reader.pages:
                text = page.extract_text()
                if text:
                    text = re.sub(r'(\r\n|\r|\n)\s*(\r\n|\r|\n)', '\n\n', text)
                    text = re.sub(r'\s{2,}', ' ', text)
                    text_blocks.append(text.strip())
            return '\n\n'.join(text_blocks)
        except Exception as e:
            print(f"Error extracting PDF content: {e}")
            raise

    def identify_section(self, text: str) -> str:
        """Identify resume section based on pattern matching."""
        text_lower = text.lower()
        for section, patterns in self.section_patterns.items():
            if any(pattern in text_lower for pattern in patterns):
                return section
        return None

    def count_sentences(self, text: str) -> int:
        """Simple sentence counter using regular expressions."""
        if not text:
            return 0
        return len(re.split(r'[.!?]+', text))

    def extract_dates(self, text: str) -> List[str]:
        """Extract dates from text."""
        if not text:
            return []
            
        date_patterns = [
            r'\b\d{4}\b',
            r'\b(?:Jan(?:uary)?|Feb(?:ruary)?|Mar(?:ch)?|Apr(?:il)?|May|Jun(?:e)?|Jul(?:y)?|Aug(?:ust)?|Sep(?:tember)?|Oct(?:ober)?|Nov(?:ember)?|Dec(?:ember)?)\s+\d{4}\b',
            r'\d{1,2}/\d{1,2}/\d{2,4}',
            r'\d{1,2}-\d{1,2}-\d{2,4}'
        ]
        
        dates = []
        for pattern in date_patterns:
            dates.extend(re.findall(pattern, text, re.IGNORECASE))
        return sorted(list(set(dates)))

    def extract_metrics(self, text: str) -> List[str]:
        """Extract metrics and achievements with numbers."""
        if not text:
            return []
            
        metric_patterns = [
            r'\$\s*\d+(?:,\d{3})*(?:\.\d{2})?(?:\s*(?:million|billion|k))?',
            r'\d+(?:,\d{3})*%',
            r'\d+(?:,\d{3})*\+?\s*(?:users|customers|clients|employees|people|projects|years)'
        ]
        
        metrics = []
        for pattern in metric_patterns:
            metrics.extend(re.findall(pattern, text, re.IGNORECASE))
        return sorted(list(set(metrics)))

    def categorize_skills(self, text: str) -> dict:
        """Categorize skills using regex pattern matching."""
        if not text:
            return {}
            
        text_lower = text.lower()
        found_skills = defaultdict(lambda: defaultdict(set))
        for main_category, subcategories in self.skill_categories.items():
            for subcategory, keywords in subcategories.items():
                for keyword in keywords:
                    pattern = rf'\b{re.escape(keyword)}\b(?:[,\s]+(?:\w+\s+){{0,3}}\w+)*'
                    matches = re.finditer(pattern, text_lower)
                    for match in matches:
                        found_skills[main_category][subcategory].add(match.group().strip())
        return {
            category: {
                subcat: sorted(list(skills))
                for subcat, skills in subcategories.items()
                if skills  # Only include non-empty skill sets
            }
            for category, subcategories in found_skills.items()
        }

    def process_resume_content(self, text: str) -> dict:
        """Process resume content with lightweight section detection and analysis."""
        if not text:
            return {
                'raw_text': '',
                'sections': {},
                'skills': {},
                'metrics': [],
                'dates': [],
                'section_statistics': {}
            }
            
        sections = defaultdict(list)
        current_section = None
        section_text = []
        lines = text.split('\n')
        for line in lines:
            line = line.strip()
            if not line:
                continue
            detected_section = self.identify_section(line)
            if detected_section:
                if current_section and section_text:
                    sections[current_section].append('\n'.join(section_text))
                    section_text = []
                current_section = detected_section
            elif current_section:
                section_text.append(line)
            else:
                # If no section detected yet, add to general section
                sections['general'].append(line)
                
        if current_section and section_text:
            sections[current_section].append('\n'.join(section_text))
            
        processed_content = {
            'raw_text': text,
            'sections': dict(sections),
            'skills': self.categorize_skills(text),
            'metrics': self.extract_metrics(text),
            'dates': self.extract_dates(text),
            'section_statistics': {
                section: {
                    'word_count': len(' '.join(content).split()),
                    'sentence_count': self.count_sentences(' '.join(content))
                }
                for section, content in sections.items()
            }
        }
        return processed_content

    async def get_ai_analysis(self, resume_content: Dict[str, Any]) -> Dict[str, Any]:
        """Generate comprehensive AI analysis with improved prompts for deeper insights"""
        try:
            if not resume_content or not isinstance(resume_content, dict):
                raise ValueError("Invalid resume content provided")
            analyses = {
                'career_trajectory': '',
                'skills_analysis': '',
                'resume_optimization': '',
                'action_plan': ''
            }
            analysis_prompts = {
                'career_trajectory': {
                    'prompt': """Analyze the career trajectory based on the provided resume data:
                            1. Career progression pattern
        - Track job titles and promotions timeline
        - Note major role transitions
        2. Key achievements
        - List quantified accomplishments
        - Highlight awards received
        3. Industry transitions
        - Document industry changes
        - Note adaptation success
        4. Leadership growth
        - Track team size managed
        - Note scope of responsibility
        5. Future potential
        - Identify next career move
        - Assess growth opportunities""",
                    'timeout': 45.0
                },
                'skills_analysis': {
                    'prompt': """Analyze the technical and professional skills:
        1. Core competencies
        - List main technical skills
        - Note proficiency levels
        2. Market relevance
        - Match skills to job requirements
        - Identify high-demand abilities
        3. Skill gaps
        - List missing critical skills
        - Suggest needed certifications
        4. Industry expertise
        - Note specialized knowledge
        - List domain experience
        5. Transferable skills
        - Identify cross-industry skills
        - List universal abilities""",
                    'timeout': 45.0
                },
                'resume_optimization': {
                    'prompt': """Optimization recommendations:
        1. Content improvements
        - Add missing metrics
        - Strengthen examples
        2. Quantification
        - Add specific numbers
        - Include scope details
        3. Key selling points
        - Highlight unique skills
        - Emphasize achievements
        4. Format suggestions
        - Improve readability
        - Enhance organization
        5. ATS optimization
        - Add relevant keywords
        - Adjust formatting""",
                    'timeout': 45.0
                },
                'action_plan': {
                    'prompt': """Action plan:
        1. Short-term goals
        - List 3-month priorities
        - Set immediate targets
        2. Medium-term goals
        - Define 1-year objectives
        - Plan major milestones
        3. Skill priorities
        - List skills to acquire
        - Identify resources
        4. Networking
        - Target key events
        - Plan connections
        5. Career steps
        - Set promotion goals
        - List target companies""",
                    'timeout': 45.0
                }
            }
            for analysis_type, config in analysis_prompts.items():
                max_retries = 2
                retry_count = 0
                while retry_count <= max_retries:
                    try:
                        # Use a safer approach to get text from resume_content
                        raw_text = resume_content.get('raw_text', '')
                        if not raw_text:
                            analyses[analysis_type] = "No resume text available for analysis."
                            break
                            
                        resume_summary = {
                            'text': raw_text[:2000],  # Limit to 2000 chars
                            'skills': resume_content.get('skills', {}),
                            'metrics': resume_content.get('metrics', []),
                            'dates': resume_content.get('dates', [])
                        }
                        
                        system_message = """You are an expert career advisor and resume analyst. 
                        Provide detailed, actionable insights based on the resume content.
                        Focus on specific examples and concrete recommendations.
                        Format your response in clear paragraphs with line breaks between main points."""
                        
                        messages = [
                            SystemMessage(content=system_message),
                            UserMessage(content=f"""Analyze this professional profile:
                            Resume Content:
                            {resume_summary['text']}
                            Professional Skills:
                            {json.dumps(resume_summary['skills'], indent=2)}
                            Career Timeline:
                            {json.dumps(resume_summary['dates'], indent=2)}
                            Key Metrics:
                            {json.dumps(resume_summary['metrics'], indent=2)}
                            Analysis Request:
                            {config['prompt']}
                            Format your response in clear paragraphs with line breaks between main points.""")
                        ]
                        
                        response = await asyncio.wait_for(
                            self.client.chat.complete_async(
                                model="mistral-medium",
                                messages=messages,
                                temperature=0.7,
                                max_tokens=1000
                            ),
                            timeout=config['timeout']
                        )
                        
                        analyses[analysis_type] = response.choices[0].message.content
                        break
                    except asyncio.TimeoutError:
                        retry_count += 1
                        if retry_count <= max_retries:
                            print(f"Timeout in {analysis_type} analysis, attempt {retry_count}/{max_retries}")
                            await asyncio.sleep(1)
                        else:
                            print(f"All retries failed for {analysis_type} analysis")
                            analyses[analysis_type] = "Analysis could not be completed due to timeout. Please try again."
                    except Exception as e:
                        print(f"Error in {analysis_type} analysis: {str(e)}\n{traceback.format_exc()}")
                        analyses[analysis_type] = f"Analysis encountered an error: {str(e)}"
                        break
                        
            if not any(analyses.values()):
                raise ValueError("No analyses could be completed")
                
            return {
                "analysis": analyses,
                "extracted_content": resume_content
            }
        except Exception as e:
            print(f"Error in AI analysis: {str(e)}\n{traceback.format_exc()}")
            raise
    
def calculate_ats_score(self, resume_content: Dict[str, Any]) -> float:
    """
    Calculate an ATS score using industry-standard criteria with adjusted weighting.
    Returns a realistic score between 55-80 based on content quality.
    """
    try:
        if not resume_content or not isinstance(resume_content, dict):
            print("Invalid resume content provided for ATS scoring.")
            return 65.0  # Default fallback score now in target range
        
        # Ensure raw_text exists and is not empty
        raw_text = resume_content.get('raw_text', '')
        if not raw_text:
            print("No raw text found in resume content.")
            return 65.0  # Default fallback score now in target range
        
        raw_text = raw_text.lower()
        sections = resume_content.get('sections', {})
        
        # FACTOR 1: KEYWORD MATCHING (30% of score)
        keyword_score = 0
        total_keywords = len(self.industry_keywords)
        matched_keywords = 0
        
        # Count how many industry keywords are found in the resume
        for keyword in self.industry_keywords:
            # Use word boundary to ensure we're matching complete words
            if re.search(r'\b' + re.escape(keyword) + r'\b', raw_text):
                matched_keywords += 1
        
        # Calculate keyword score based on percentage of matched keywords
        keyword_match_percentage = matched_keywords / total_keywords if total_keywords > 0 else 0
        keyword_score = min(30 * keyword_match_percentage, 30)
        
        # Add a base score to avoid too low values
        if keyword_score < 15:
            keyword_score = 15 + (keyword_score / 2)
        
        # FACTOR 2: RESUME STRUCTURE (20% of score)
        structure_score = 0
        essential_sections = ['experience', 'education', 'skills']
        important_sections = ['summary', 'projects', 'certifications']
        
        # Check for essential sections (12%)
        for section in essential_sections:
            if section in sections:
                structure_score += 4  # Adjusted weight
        
        # Check for important sections (8%)
        for section in important_sections:
            if section in sections:
                structure_score += 2.67  # Adjusted weight to total 8%
        
        # Cap structure score at 20
        structure_score = min(structure_score, 20)
        
        # Ensure minimum structure score
        structure_score = max(structure_score, 10)
        
        # FACTOR 3: EXPERIENCE & EDUCATION QUALITY (20% of score)
        quality_score = 0
        
        # Check for quantifiable metrics (up to 12%)
        metrics = resume_content.get('metrics', [])
        if not isinstance(metrics, list):
            metrics = []
        
        # More granular scoring based on number of metrics
        if len(metrics) >= 5:
            quality_score += 12  # Full points for 5+ metrics
        elif len(metrics) > 0:
            quality_score += 6 + (len(metrics) * 1.5)  # Scale based on count with higher base
        else:
            quality_score += 6  # Higher base score
        
        # Check for detailed dates (up to 8%)
        dates = resume_content.get('dates', [])
        if not isinstance(dates, list):
            dates = []
            
        if len(dates) >= 4:
            quality_score += 8  # Full points for 4+ date references
        elif len(dates) > 0:
            quality_score += 4 + (len(dates))  # Scale based on count with higher base
        else:
            quality_score += 4  # Higher base score
        
        # Cap quality score at 20
        quality_score = min(quality_score, 20)
        
        # FACTOR 4: FORMATTING & READABILITY (15% of score)
        format_score = 0
        
        # Check resume length (5%)
        word_count = len(raw_text.split())
        if word_count >= 500:
            format_score += 5  # Ideal length
        elif word_count >= 300:
            format_score += 4
        elif word_count >= 200:
            format_score += 3.5
        else:
            format_score += 3  # Too short but higher minimum
        
        # Check for clean section formatting (5%)
        if len(sections) >= 5:
            format_score += 5  # Comprehensive sections
        elif len(sections) >= 3:
            format_score += 4
        else:
            format_score += 3  # Poor sectioning but higher minimum
        
        # Check for bullet points (5%)
        bullet_pattern = r'^\s*[â€¢\-*]\s'
        bullets = re.findall(bullet_pattern, raw_text, re.MULTILINE)
        if len(bullets) >= 10:
            format_score += 5  # Well-formatted with bullets
        elif len(bullets) >= 5:
            format_score += 4
        elif len(bullets) > 0:
            format_score += 3
        else:
            format_score += 2  # No bullet formatting but higher minimum
        
        # BASE SCORE (15% of total)
        # Add a fixed base score to shift all results higher
        base_score = 15
        
        # Calculate final score (100 point scale)
        final_score = keyword_score + structure_score + quality_score + format_score + base_score
        
        # Add small variance for natural distribution
        import random
        # Smaller variance to keep within target range
        variation = random.uniform(-1.0, 1.0)
        final_score += variation
        
        # Ensure score is between 55-80 with soft clamping to avoid too many edge scores
        if final_score < 55:
            # Soft clamping for scores below range
            adjustment = (55 - final_score) * 0.8
            final_score += adjustment
        elif final_score > 80:
            # Soft clamping for scores above range
            adjustment = (final_score - 40) * 0.8
            final_score -= adjustment
            
        # Ensure absolute limits
        final_score = max(min(final_score, 80), 55)
        
        # Round to nearest tenth
        return round(final_score, 1)
        
    except Exception as e:
        print(f"Error calculating ATS score: {str(e)}\n{traceback.format_exc()}")
        return 65.0  # Return a moderate default score in target range
            
async def analyze_resume(self, file_path: str) -> Dict[str, Any]:
        """Perform comprehensive resume analysis with detailed insights."""
        try:
            with open(file_path, 'rb') as file:
                file_content = file.read()
                
            # Only accept PDF files
            file_extension = os.path.splitext(file_path)[1].lower()
            if file_extension != '.pdf':
                raise ValueError(f"Unsupported file type: {file_extension}. Only PDF files are supported.")
                
            raw_text = self.extract_text_from_pdf(file_content)
            processed_content = self.process_resume_content(raw_text)
            analysis = await self.get_ai_analysis(processed_content)
            ats_score = self.calculate_ats_score(processed_content)
            return {
                "analysis": analysis["analysis"],
                "extracted_content": processed_content,
                "ats_score": ats_score,
                "timestamp": datetime.now().isoformat(),
                "version": "2.0.0"
            }
        except Exception as e:
            print(f"Error in resume analysis: {e}")
            raise
            
async def main():
    """Main function with enhanced error handling and output formatting."""
    try:
        mistral_api_key = "YOUR_MISTRAL_API_KEY"
        if not mistral_api_key:
            raise ValueError("MISTRAL_API_KEY environment variable not set")
        analyzer = EnhancedResumeAnalyzer(mistral_api_key)
        pdf_path = "Resume.pdf"
        if not os.path.exists(pdf_path):
            raise FileNotFoundError(f"Resume file not found: {pdf_path}")
        print("\nAnalyzing resume... This may take a few moments.\n")
        results = await analyzer.analyze_resume(pdf_path)
        print("\n=== Career Development Analysis ===\n")
        print(results["analysis"]["career_trajectory"])
        print("\n=== Skills Assessment ===\n")
        print(results["analysis"]["skills_analysis"])
        print("\n=== Resume Optimization Recommendations ===\n")
        print(results["analysis"]["resume_optimization"])
        print("\n=== Action Plan ===\n")
        print(results["analysis"]["action_plan"])
        print(f"\n=== ATS Score ===\nATS Score: {results.get('ats_score', 'N/A')}%")
        output_file = f"resume_analysis_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        with open(output_file, 'w') as f:
            json.dump(results, f, indent=2)
        print(f"\nDetailed analysis saved to: {output_file}")
    except Exception as e:
        print(f"Error: {e}")
        raise

if __name__ == "__main__":
    asyncio.run(main())